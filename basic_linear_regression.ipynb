{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic_linear_regression: \n",
    "A simple single layer pytorch model to show how ```torch.nn.Linear``` solves general multi-variate linear regression problems\n",
    "\n",
    "___\n",
    "### Idea:\n",
    "The pytorch nn.Linear class can solve general Linear Equations of the kind:  $$\\mathbf{y} = \\mathbf{x}\\mathbf{A^\\top} + b$$ where:\n",
    "* $\\mathbf{A}$ is a transformation matrix which represent coefficients of the equation, \n",
    "* $\\mathbf{x}$ is a vector of inputs and \n",
    "* $\\mathbf{y}$ is a vector that is the result of the linear transformation\n",
    "\n",
    "We are given: \n",
    "* rows of $\\mathbf{x}$ values in a matrix $\\mathbf{X}$,\n",
    "* rows of $\\mathbf{y}$ values in a matrix $\\mathbf{Y}$\n",
    "\n",
    "The model <span style=\"color:blue\">SingleLayerNet</span> solves for the transformation matrix $\\mathbf{A}$.\n",
    "\n",
    "___\n",
    "### Use:\n",
    "##### In section 1.0\n",
    "* set the scalar variable ```number_of_coefficients```\n",
    " * this variable determines the number of columns in Matrix $\\mathbf{A}$\n",
    "* set the scalar variable ```y_dimension```\n",
    " * the y_dimension determines:\n",
    "   * the size of the $\\mathbf{y}$ vector output of the linear transformation\n",
    "   * this variable determines the number of rows in Matrix $\\mathbf{A}$\n",
    "* set the scalar bias term\n",
    "* a scalar, (e.g. 0.1) in order to add some normally distributed random noise to the linear transformation\n",
    "\n",
    "```\n",
    "# exzmple from section 1.0\n",
    "number_of_coefficients=3\n",
    "y_dimension=number_of_coefficients\n",
    "bias = 1\n",
    "noise_level = 0.1\n",
    "```\n",
    "\n",
    "##### In section 2.0:\n",
    "* run all cells from 2.0 on \n",
    "\n",
    "##### In section 3.0:\n",
    "* run a single $\\mathbf{x}$ vector test to see if the model's coefficients work\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 1.0 - Set the values below to determine: \n",
    "* the shape of matrix $\\mathbf{A}$\n",
    "* the shape of the output vector $\\mathbf{y}$\n",
    "* the amount of bias (the b term of the above linear equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_coefficients=3\n",
    "y_dimension=number_of_coefficients\n",
    "bias = 1\n",
    "noise_level = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2.0  - Run all cells below to determine the values in the matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.01 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bperlman1/Virtualenvs3/pyliverisk/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypg.pg_pandas as pg\n",
    "import os,sys\n",
    "import pdb\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.02 ```create_x_values``` creates a single row of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method builds test y values/vectors for training\n",
    "def create_x_values(x_vector):\n",
    "    m = number_of_coefficients\n",
    "    A = np.linspace(1,m,m).repeat(m).reshape(-1,m)\n",
    "    return np.matmul(A,x_vector) + bias + np.random.randn() * noise_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.03 Define the SingleLayerNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model class\n",
    "class SingleLayerNet(nn.Module):\n",
    "  def __init__(self, D_in, D_out):\n",
    "    super(SingleLayerNet, self).__init__()\n",
    "    self.linear1 = nn.Linear(D_in, D_out) \n",
    "  def forward(self, x):\n",
    "    return self.linear1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bperlman1/Virtualenvs3/pyliverisk/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/Users/bperlman1/Virtualenvs3/pyliverisk/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 6075.51123046875\n",
      "epoch 500, loss 16.192283630371094\n",
      "epoch 1000, loss 8.863194465637207\n",
      "epoch 1500, loss 5.04934024810791\n",
      "epoch 2000, loss 2.679178237915039\n",
      "epoch 2500, loss 3.3506500720977783\n",
      "epoch 3000, loss 2.822608470916748\n",
      "epoch 3500, loss 4.0402326583862305\n",
      "epoch 4000, loss 3.608442544937134\n",
      "epoch 4500, loss 2.945143938064575\n",
      "epoch 5000, loss 3.089378595352173\n",
      "epoch 5500, loss 3.0989437103271484\n",
      "epoch 6000, loss 3.0009024143218994\n",
      "epoch 6500, loss 2.9494965076446533\n",
      "A = [[1.0062019 1.0010154 0.9928246]\n",
      " [2.0036192 2.0022457 1.9948812]\n",
      " [3.0040717 3.0039475 2.9970388]]\n",
      "bias = [0.9933811  0.99323434 0.9940275 ]\n"
     ]
    }
   ],
   "source": [
    "# number of training rows\n",
    "n=10000\n",
    "# number of elements in each batch on each epoch\n",
    "b=100\n",
    "# number of epochs\n",
    "epochs=7000\n",
    "# instantiate model\n",
    "m1 = SingleLayerNet(number_of_coefficients,y_dimension)\n",
    "# Create input torch Variables for X and Y\n",
    "Xnp = np.random.rand(n,number_of_coefficients)\n",
    "X = Variable(torch.Tensor(Xnp))\n",
    "Ynp = np.array([create_x_values(x) for x in X])\n",
    "Y = Variable(torch.Tensor(Ynp).reshape(-1,number_of_coefficients))\n",
    "\n",
    "# create loss and optimizer\n",
    "loss_fn = torch.nn.MSELoss(size_average = False) \n",
    "optimizer = optim.Adam(m1.parameters(), lr = 0.01)\n",
    "\n",
    "# Training loop\n",
    "for i in range(epochs):\n",
    "    # create a batch of x values and y values (labels)\n",
    "    indices = list(range(n))\n",
    "    np.random.shuffle(indices)\n",
    "    xb = X[indices[:b]]    \n",
    "    yb = Y[indices][:b]\n",
    "    # zero the optimizer\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    \n",
    "    # execute the forward pass to compute y values from equation xA^T + b (the linear transformation)\n",
    "    output_batch = m1(xb)           # compute model output\n",
    "    \n",
    "    # calculate a loss\n",
    "    loss = loss_fn(output_batch, yb)  # calculate loss\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "    optimizer.step()       # perform updates using calculated gradients\n",
    "    # print out progress\n",
    "    if i % 500 == 0 :\n",
    "        print('epoch {}, loss {}'.format(i,loss.data[0]))\n",
    "\n",
    "# print model results\n",
    "model_A = m1.linear1.weight.data.numpy()\n",
    "model_bias = m1.linear1.bias.data.numpy()\n",
    "print(f'A = {model_A}')\n",
    "print(f'bias = {model_bias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3.0 run a test on a single x vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example x value [1. 2. 3.]\n",
      "example y value to predict [ 7.1710942 13.1710942 19.1710942]\n",
      "example y prediction [[ 6.9800878 12.985989  18.99711  ]]\n",
      "difference =  [[0.191  0.1851 0.174 ]]\n"
     ]
    }
   ],
   "source": [
    "example_x = np.linspace(1,number_of_coefficients,number_of_coefficients)\n",
    "print(f'example x value {example_x}')\n",
    "example_y = create_x_values(example_x)\n",
    "print(f'example y value to predict {example_y}')\n",
    "example_prediction = m1(torch.Tensor(example_x.reshape(-1,number_of_coefficients))).data.numpy()\n",
    "print(f'example y prediction {example_prediction}')\n",
    "diffs = example_y - example_prediction\n",
    "print(f'difference =  {diffs.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
