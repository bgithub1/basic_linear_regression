{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic_linear_regression: \n",
    "A simple single layer pytorch model to show how ```torch.nn.Linear``` solves general multi-variate linear regression problems.  \n",
    "(_Tested using python3_)\n",
    "\n",
    "___\n",
    "### Idea:\n",
    "The pytorch nn.Linear class can solve general Linear Equations of the kind:  $$\\mathbf{y} = \\mathbf{x}\\mathbf{A^\\top} + b$$ where:\n",
    "* $\\mathbf{A}$ is a transformation matrix which represent coefficients of the equation, \n",
    "* $\\mathbf{x}$ is a vector of inputs and \n",
    "* $\\mathbf{y}$ is a vector that is the result of the linear transformation\n",
    "\n",
    "We are given: \n",
    "* rows of $\\mathbf{x}$ values in a matrix $\\mathbf{X}$,\n",
    "* rows of $\\mathbf{y}$ values in a matrix $\\mathbf{Y}$\n",
    "\n",
    "The model <span style=\"color:blue\">SingleLayerNet</span> solves for the transformation matrix $\\mathbf{A}$.\n",
    "\n",
    "___\n",
    "### Use:\n",
    "##### In section 1.0\n",
    "* set the scalar variable ```number_of_coefficients```\n",
    " * this variable determines the number of columns in Matrix $\\mathbf{A}$\n",
    "* set the scalar variable ```y_dimension```\n",
    " * the y_dimension determines:\n",
    "   * the size of the $\\mathbf{y}$ vector output of the linear transformation\n",
    "   * this variable determines the number of rows in Matrix $\\mathbf{A}$\n",
    "* set the scalar bias term\n",
    "* a scalar, (e.g. 0.1) in order to add some normally distributed random noise to the linear transformation\n",
    "\n",
    "```\n",
    "# exzmple from section 1.0\n",
    "number_of_coefficients=3\n",
    "y_dimension=number_of_coefficients\n",
    "bias = 1\n",
    "noise_level = 0.1\n",
    "```\n",
    "\n",
    "##### In section 2.0:\n",
    "* run all cells from 2.0 on \n",
    "\n",
    "##### In section 3.0:\n",
    "* run a single $\\mathbf{x}$ vector test to see if the model's coefficients work\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 1.0 - Set the values below to determine: \n",
    "* the shape of matrix $\\mathbf{A}$\n",
    "* the shape of the output vector $\\mathbf{y}$\n",
    "* the amount of bias (the b term of the above linear equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_coefficients=3\n",
    "y_dimension=number_of_coefficients\n",
    "bias = 1\n",
    "noise_level = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2.0  - Run all cells below to determine the values in the matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.01 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypg.pg_pandas as pg\n",
    "import os,sys\n",
    "import pdb\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.02 ```create_x_values``` creates a single row of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method builds test y values/vectors for training\n",
    "def create_x_values(x_vector):\n",
    "    m = number_of_coefficients\n",
    "    A = np.linspace(1,m,m).repeat(m).reshape(-1,m)\n",
    "    return np.matmul(A,x_vector) + bias + np.random.randn() * noise_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.03 Define the SingleLayerNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model class\n",
    "class SingleLayerNet(nn.Module):\n",
    "  def __init__(self, D_in, D_out):\n",
    "    super(SingleLayerNet, self).__init__()\n",
    "    self.linear1 = nn.Linear(D_in, D_out) \n",
    "  def forward(self, x):\n",
    "    return self.linear1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training rows\n",
    "n=10000\n",
    "# number of elements in each batch on each epoch\n",
    "b=100\n",
    "# number of epochs\n",
    "epochs=7000\n",
    "# instantiate model\n",
    "m1 = SingleLayerNet(number_of_coefficients,y_dimension)\n",
    "# Create input torch Variables for X and Y\n",
    "Xnp = np.random.rand(n,number_of_coefficients)\n",
    "X = Variable(torch.Tensor(Xnp))\n",
    "Ynp = np.array([create_x_values(x) for x in X])\n",
    "Y = Variable(torch.Tensor(Ynp).reshape(-1,number_of_coefficients))\n",
    "\n",
    "# create loss and optimizer\n",
    "loss_fn = torch.nn.MSELoss(size_average = False) \n",
    "optimizer = optim.Adam(m1.parameters(), lr = 0.01)\n",
    "\n",
    "# Training loop\n",
    "for i in range(epochs):\n",
    "    # create a batch of x values and y values (labels)\n",
    "    indices = list(range(n))\n",
    "    np.random.shuffle(indices)\n",
    "    xb = X[indices[:b]]    \n",
    "    yb = Y[indices][:b]\n",
    "    # zero the optimizer\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    \n",
    "    # execute the forward pass to compute y values from equation xA^T + b (the linear transformation)\n",
    "    output_batch = m1(xb)           # compute model output\n",
    "    \n",
    "    # calculate a loss\n",
    "    loss = loss_fn(output_batch, yb)  # calculate loss\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "    optimizer.step()       # perform updates using calculated gradients\n",
    "    # print out progress\n",
    "    if i % 500 == 0 :\n",
    "        print('epoch {}, loss {}'.format(i,loss.data[0]))\n",
    "\n",
    "# print model results\n",
    "model_A = m1.linear1.weight.data.numpy()\n",
    "model_bias = m1.linear1.bias.data.numpy()\n",
    "print(f'A = {model_A}')\n",
    "print(f'bias = {model_bias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3.0 run a test on a single x vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_x = np.linspace(1,number_of_coefficients,number_of_coefficients)\n",
    "print(f'example x value {example_x}')\n",
    "example_y = create_x_values(example_x)\n",
    "print(f'example y value to predict {example_y}')\n",
    "example_prediction = m1(torch.Tensor(example_x.reshape(-1,number_of_coefficients))).data.numpy()\n",
    "print(f'example y prediction {example_prediction}')\n",
    "diffs = example_y - example_prediction\n",
    "print(f'difference =  {diffs.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
